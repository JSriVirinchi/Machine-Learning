{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 6.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNqkjrVsRCVvaOKQ/AY28Ai"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dqeGQbnn6_sQ"},"source":["Mounting google drive"]},{"cell_type":"code","metadata":{"id":"2VaYKtO_66ux"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nL8uL9fU7GO_"},"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import fnmatch\n","import os\n","import keras\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n","from keras.layers.core import Flatten, Dense, Dropout\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, History, ReduceLROnPlateau, CSVLogger\n","from keras.metrics import*\n","from keras.models import*\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing import image\n","import time\n","from tqdm import tqdm_notebook as tqdm\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.manifold import TSNE\n","from keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications import ResNet50\n","from keras.applications.inception_v3 import InceptionV3\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import seaborn as sns\n","import datetime as dt\n","import h5py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wr9uA0VlXocD"},"source":["Load Data"]},{"cell_type":"code","metadata":{"id":"uCH0aHU9PCfW"},"source":["path = \"/content/drive/MyDrive/plant-seedlings-classification/train/\"\n","label_nums = {'Loose Silky-bent':0, 'Charlock':1, 'Sugar beet':2, 'Small-flowered Cranesbill':3,'Common Chickweed':4, 'Common wheat':5, \n","             'Maize':6, 'Cleavers':7, 'Scentless Mayweed':8,'Fat Hen':9, 'Black-grass':10, 'Shepherds Purse':11}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Coiwd8oNPeXH"},"source":["train_label = []\n","train_img = []\n","\n","for i in os.listdir(path):\n","    label_number = label_nums[i]\n","    new_path = path+i+'/'\n","    for j in fnmatch.filter(os.listdir(new_path), '*.png'):\n","        temp_img = keras.preprocessing.image.load_img(new_path+j, target_size=(128,128))\n","        temp_img = keras.preprocessing.image.img_to_array(temp_img)\n","        train_img.append(temp_img)\n","        train_label.append(label_number)\n","\n","train_img = np.array(train_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gyPrVfljXZpg"},"source":["One Hot Encoding"]},{"cell_type":"code","metadata":{"id":"_qYe0B7iPpms"},"source":["train_label=np.array(pd.get_dummies(train_label))\n","print(train_img.shape)\n","print(train_label.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-FSRUchKYumB"},"source":["Seeing how data is distributed"]},{"cell_type":"code","metadata":{"id":"13bgwbT_W63P"},"source":["categories = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n","dict1={}\n","for i in categories:\n","  dict1[i]=len(os.listdir(os.path.join(path, i)))\n","  print(i,dict1[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EoXbE0f5aqiV"},"source":["Data for each category has varying number of images, where loos silky bent category has 654 images and maize has only 221 images "]},{"cell_type":"markdown","metadata":{"id":"qvRCu4lobAlP"},"source":["Normalising "]},{"cell_type":"code","metadata":{"id":"93vHyc1IYmcH"},"source":["train_img = train_img/255"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ifImVT3ElE8C"},"source":["**Visualising sample Images of 12 categories**"]},{"cell_type":"code","metadata":{"id":"IhtqZIoxbFxi"},"source":["for i in range(0,12):\n","  plt.figure()\n","  for (img, label) in zip(train_img ,train_label):\n","    if (label[i]==1):\n","      plt.imshow(img)\n","      plt.title(categories[i])\n","      break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZUUHPfOttYkZ"},"source":["**Balancing the data**"]},{"cell_type":"code","metadata":{"id":"0Rj_zRx2bzhl"},"source":["#calculating number of images to be added to the category\n","num_of_img_to_add = []\n","for i in range(12):\n","  num_of_img_to_add.append(654 - (dict1[categories[i]]))\n","num_of_img_to_add = np.array(num_of_img_to_add)\n","print(num_of_img_to_add)\n","print(num_of_img_to_add.sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKn9fe6m-tKO"},"source":["#training set after data augmentation inititalisation\n","data_augmented_train_img = train_img\n","data_augmented_train_label = train_label\n","\n","print(data_augmented_train_img.shape, data_augmented_train_label.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDi3zMQ8t2UD"},"source":["#creating new images based on the number of images required per category\n","#sharpening matrix\n","sharpening = np.array([ [-1, -1, -1],\n","                        [-1, 10, -1],\n","                        [-1, -1, -1]])\n","arr = []\n","labels = []\n","\n","while (num_of_img_to_add.sum() > 0 ):\n","  for (img, label) in zip(train_img ,train_label):\n","    if (num_of_img_to_add[label.argmax()] > 0):\n","      temp_img = img\n","      #randomising various cv2 actions like rotating, flipping, sharpening\n","      random_nums = np.random.randint(0,2,5)\n","      #sharpening\n","      if (random_nums[0]):\n","        temp_img = cv2.filter2D(temp_img, -1, sharpening)\n","      #flipping\n","      if (random_nums[1]):\n","        temp_img = cv2.flip(temp_img, 1)\n","      #rotating\n","      if (random_nums[2]):\n","        temp_img = cv2.rotate(temp_img, rotateCode= cv2.ROTATE_180)\n","      if (random_nums[3]):\n","        temp_img = cv2.rotate(temp_img, rotateCode= cv2.ROTATE_90_COUNTERCLOCKWISE)\n","      if (random_nums[4]):\n","        temp_img = cv2.rotate(temp_img, rotateCode= cv2.ROTATE_90_CLOCKWISE)\n","      \n","      num_of_img_to_add[label.argmax()]-= 1\n","      #append to augmented dataset\n","      arr.append(temp_img)\n","      labels.append(label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wKGDosqkwKoI"},"source":["print(len(arr), len(labels), num_of_img_to_add)\n","# Extra 3088 images are augmented. And array of 12 zeroes indicate that there is no imbalance and all the classes have equal number of images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qOeQmZUOLAFp"},"source":["#using asarray to concatenate later\n","arr = np.asarray(arr)\n","labels = np.asarray(labels)\n","print(arr.shape,labels.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BHdl6uJRG17o"},"source":["data_augmented_train_img = np.concatenate((train_img, arr),axis=0)\n","data_augmented_train_label = np.concatenate((train_label,labels),axis=0)\n","\n","print(data_augmented_train_img.shape, data_augmented_train_label.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8XnVtom5Mka5"},"source":["In the given dataset, there are 12 categories and the data is not balanced and the number of images for each class is different. Highest number of images per class was 654 and lowest was upto 221 images as seen earlier.\n","Now all the classes have 654 images by using data augmentation using rotations, flipping, sharpenening randomly.\n","So 654*12 = 7848.\n","So, the shape for data augmented train images is (7848,128,128,3) and for labels, it is (7848, 12) "]},{"cell_type":"markdown","metadata":{"id":"ddDBsco2OBoQ"},"source":["**Splitting into train and test**"]},{"cell_type":"code","metadata":{"id":"vqRQ3YMXK3ZL"},"source":["random_seed = 0\n","X_train, X_test, Y_train, Y_test = train_test_split(data_augmented_train_img , data_augmented_train_label,test_size=0.1, random_state=random_seed)\n","X_valid, X_test_new, Y_valid, Y_test_new=train_test_split(data_augmented_train_img,data_augmented_train_label,test_size=0.5, random_state=random_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOvhyMGrO8rW"},"source":["print(X_train.shape, X_test.shape, Y_train.shape,Y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iw2rO0BZPTIW"},"source":["**Inception model**"]},{"cell_type":"markdown","metadata":{"id":"e3O6yPwjWT5C"},"source":["Model"]},{"cell_type":"code","metadata":{"id":"bQPuQ56sPEXg"},"source":["base_model = InceptionV3(include_top= False, pooling='avg', weights=\"imagenet\")\n","\n","fine_tune_at=150\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable=False\n","\n","model_1=keras.Sequential()\n","model_1.add(base_model)\n","\n","#Overfitting. so dropout added\n","model_1.add(Dropout(0.4))\n","model_1.add(Flatten())\n","\n","# Dense layer and l2 regularization\n","model_1.add(Dense(1024, activation='relu', kernel_regularizer='l2'))\n","# softmax with 12 outputs\n","model_1.add(Dense(12, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GODTfnA6WVee"},"source":["Compile and fit"]},{"cell_type":"code","metadata":{"id":"lerlDjIdU7Fc"},"source":["learning_rate = 0.001\n","adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n","model_1.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HVWmh7YIWbce"},"source":["epochs = 100\n","batch_size = 128\n","#Early stopping\n","earlystopper = EarlyStopping(patience=10, verbose=0)\n","#Reduced lr plateau\n","lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.85, patience=10, min_lr=0.0001)\n","#Modelcheckpoint to save the best model\n","check=ModelCheckpoint('best_model_inception.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n","history=model_1.fit(X_train, Y_train, validation_data= (X_valid, Y_valid), shuffle=True, epochs=epochs, batch_size=batch_size, callbacks=[earlystopper, lr_reduce,check], verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDAcJ8HcLEKO"},"source":["Loss, accuracy vs epochs"]},{"cell_type":"code","metadata":{"id":"RgOh9l3TEH2u"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([0,1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t77Tn-d7LYJI"},"source":["Save model"]},{"cell_type":"code","metadata":{"id":"j6jqTxzUKIZd"},"source":["saved_model_1 = load_model(\"best_model_inception.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2pRkOBNiKMWV"},"source":["Confusion matrix and classification report"]},{"cell_type":"code","metadata":{"id":"DtahGf6GKLJ6"},"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","y_pred = saved_model_1.predict(X_test_new)\n","y_pred_Classes = np.argmax(y_pred, axis = 1)\n","trueY = np.argmax(Y_test_new, axis = 1) \n","\n","# confusion matrix\n","cm = confusion_matrix(trueY, y_pred_Classes)\n","print(cm)\n","print(classification_report(trueY, y_pred_Classes))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vr5IqCzOKbnw"},"source":["**VGG 16**"]},{"cell_type":"markdown","metadata":{"id":"CPUVkEQdKhpN"},"source":["Model"]},{"cell_type":"code","metadata":{"id":"kqW4AEBtKLVs"},"source":["base_model_2 = VGG16(include_top=False, pooling='avg', weights=\"imagenet\")\n","#fine tuning increased the accuracy, keeping trainable as True did not give good results\n","fine_tune_at=150\n","for layer in base_model_2.layers[:fine_tune_at]:\n","  layer.trainable=False\n","#base_model_2.trainable=True\n","model_2=Sequential()\n","model_2.add(base_model_2)\n","model_2.add(Flatten())\n","#model_2.add(Dropout(0.25))\n","# Add a new Dense layer to fully connect the node\n","model_2.add(Dense(512, activation='relu'))\n","model_2.add(Dropout(0.25))\n","model_2.add(Dense(512, activation='relu'))\n","model_2.add(Dropout(0.25))\n","# Add a new Dense layer to output 12 classes\n","# Initialize the weight with Xavier Normal Initialization\n","model_2.add(Dense(12, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8kdhRHPOKjXO"},"source":["Compile and fit"]},{"cell_type":"code","metadata":{"id":"UMnCGivoKsX_"},"source":["learning_rate = 0.001\n","adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n","model_2.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlSoEfeyK9Z2"},"source":["epochs = 100\n","batch_size = 128\n","#Early stopping\n","earlystopper = EarlyStopping(patience=15, verbose=0)\n","#Reduced LR\n","lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.85, patience=10, min_lr=0.0001)\n","#ModelCheckpoint to save the best model\n","check=ModelCheckpoint('best_model_vgg16.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n","history_2=model_2.fit(X_train, Y_train, validation_data= (X_valid, Y_valid), epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[earlystopper, lr_reduce, check], verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q__GXa5qK2RK"},"source":["Loss and accuracy vs epoch"]},{"cell_type":"code","metadata":{"id":"v7qgjnAmLNbF"},"source":["acc = history_2.history['accuracy']\n","val_acc = history_2.history['val_accuracy']\n","\n","loss = history_2.history['loss']\n","val_loss = history_2.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([0,1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpCV1Hq9LU9h"},"source":["Save model"]},{"cell_type":"code","metadata":{"id":"FCq7IyIOLSZR"},"source":["saved_model_2 = load_model(\"best_model_vgg16.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMLtDD1PLfTr"},"source":["Confusion matrix and classification report"]},{"cell_type":"code","metadata":{"id":"qgVOV_ifLWhy"},"source":["y_pred = saved_model_2.predict(X_test_new)\n","y_pred_Classes = np.argmax(y_pred, axis = 1)\n","trueY = np.argmax(Y_test_new, axis = 1) \n","\n","# confusion matrix\n","cm = confusion_matrix(trueY, y_pred_Classes)\n","print(cm)\n","print(classification_report(trueY, y_pred_Classes))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oXJSx5gnLosl"},"source":["**ResNet 50**"]},{"cell_type":"markdown","metadata":{"id":"a3Y8qHtgMFE2"},"source":["Model"]},{"cell_type":"code","metadata":{"id":"LjyB49wNLbPQ"},"source":["base_model_3 = ResNet50(include_top=False, weights=\"imagenet\", pooling='avg')\n","#Model was giving very low accuracy hence trainable had to be set false for layers and after this the accuracy improved\n","for i in range(len(model_3.layers)-1):\n","  model_3.layers[i].trainable=False\n","#base_model_3.trainable=True\n","model_3=Sequential()\n","model_3.add(base_model_3)\n","model_3.add(Flatten())\n","model_3.add(Dropout(0.4))\n","# Add a new Dense layer to fully connect the node\n","model_3.add(Dense(1024, activation='relu'))\n","model_3.add(Dropout(0.2))\n","#Only one FC added as model was ovefitting a lot on having 2 FC\n","#model_3.add(Dense(512, activation='relu'))\n","#model_3.add(Dropout(0.2))\n","# Add a new Dense layer to output 12 classes\n","model_3.add(Dense(12, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z_RvrvZlMGqs"},"source":["Compile and fit"]},{"cell_type":"code","metadata":{"id":"iHhruzF6MJ6e"},"source":["learning_rate = 0.001\n","adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n","model_3.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gbsng6FxfudD"},"source":["epochs = 150\n","batch_size = 128\n","earlystopper = EarlyStopping(patience=15, verbose=0)\n","lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.85, patience=10, min_lr=0.0001)\n","check=ModelCheckpoint('best_model_resnet50.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n","#Though ModelCheckPoint has been added but this saved model was not loaded because in resnet there was problem in printing confusion matrix\n","history_3=model_3.fit(X_train, Y_train, validation_data= (X_valid, Y_valid), epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[earlystopper, lr_reduce], verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BT-wVZUtf1Z5"},"source":["Loss and accuracy vs epoch"]},{"cell_type":"code","metadata":{"id":"4aWMBvLVf3x0"},"source":["acc = history_3.history['accuracy']\n","val_acc = history_3.history['val_accuracy']\n","\n","loss = history_3.history['loss']\n","val_loss = history_3.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([0,1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEtUIfVRf63b"},"source":["Save model"]},{"cell_type":"code","metadata":{"id":"JjUUyGGEf9Ij"},"source":["saved_model_3 = load_model(\"best_model_resnet50.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--hApSzaf4r_"},"source":["Confusion matrix and classification report"]},{"cell_type":"code","metadata":{"id":"ZbWPNXSlgC3U"},"source":["y_pred =model_3.predict(X_test_new)\n","y_pred_Classes = np.argmax(y_pred, axis = 1)\n","trueY = np.argmax(Y_test_new, axis = 1) \n","\n","# confusion matrix\n","cm = confusion_matrix(trueY, y_pred_Classes)\n","print(cm)\n","print(classification_report(trueY, y_pred_Classes))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gibjzwU9gE5P"},"source":[""]}]}